{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>date_created</th>\n",
       "      <th>number_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>self_post</th>\n",
       "      <th>sub</th>\n",
       "      <th>submission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All In The War Machine</td>\n",
       "      <td>eld4i6</td>\n",
       "      <td>https://i.redd.it/cj2vw26nmd941.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.578440e+09</td>\n",
       "      <td>780.0</td>\n",
       "      <td>everythingorange9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wsb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to get oil back up</td>\n",
       "      <td>g55or2</td>\n",
       "      <td>https://i.redd.it/w5iqqihjo2u41.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.587461e+09</td>\n",
       "      <td>516.0</td>\n",
       "      <td>futuretrollshark</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wsb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Type yy into google.</td>\n",
       "      <td>c75d5x</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>That’s all I’m saying.</td>\n",
       "      <td>1.561875e+09</td>\n",
       "      <td>17281.0</td>\n",
       "      <td>Alopez2897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wsb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oil is now expenzive</td>\n",
       "      <td>d51f4o</td>\n",
       "      <td>https://i.redd.it/2j386s5iuym31.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.568673e+09</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wsb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My dad, working through a 15-hour time zone di...</td>\n",
       "      <td>d29nov</td>\n",
       "      <td>https://i.redd.it/60asaz4zhsl31.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.568160e+09</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>SerraTL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wsb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      id  \\\n",
       "0                             All In The War Machine  eld4i6   \n",
       "1                             How to get oil back up  g55or2   \n",
       "2                               Type yy into google.  c75d5x   \n",
       "3                               Oil is now expenzive  d51f4o   \n",
       "4  My dad, working through a 15-hour time zone di...  d29nov   \n",
       "\n",
       "                                                 url                    body  \\\n",
       "0                https://i.redd.it/cj2vw26nmd941.jpg                     NaN   \n",
       "1                https://i.redd.it/w5iqqihjo2u41.jpg                     NaN   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...  That’s all I’m saying.   \n",
       "3                https://i.redd.it/2j386s5iuym31.png                     NaN   \n",
       "4                https://i.redd.it/60asaz4zhsl31.jpg                     NaN   \n",
       "\n",
       "   date_created  number_comments             author  self_post  sub  \\\n",
       "0  1.578440e+09            780.0  everythingorange9        0.0  wsb   \n",
       "1  1.587461e+09            516.0   futuretrollshark        0.0  wsb   \n",
       "2  1.561875e+09          17281.0         Alopez2897        1.0  wsb   \n",
       "3  1.568673e+09           1019.0                NaN        0.0  wsb   \n",
       "4  1.568160e+09           1633.0            SerraTL        0.0  wsb   \n",
       "\n",
       "   submission  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing like this to make sure the datatypes work and are correct\n",
    "dtyping ={\n",
    "    'title' : str,\n",
    "    'url' : str,\n",
    "    'author' : str \n",
    "}\n",
    "df = pd.read_csv('./data/wsb_and_btc_all.csv', dtype=dtyping)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Titles\n",
    "df_titles = df[['title', 'sub']].copy()\n",
    "df_titles.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling a random sample from the dataset because the whole dataset\n",
    "# is taking way too long to model\n",
    "df_samp = df.groupby('sub').apply(lambda x: x.sample(n=20_000, random_state = 42))\n",
    "\n",
    "\n",
    "#adapted from https://stackoverflow.com/questions/41035187/stratified-samples-from-pandas\n",
    "# Comments + Body\n",
    "df_com_bod = df_samp[['sub', 'body']].copy()\n",
    "\n",
    "df_com_bod.dropna(inplace=True)\n",
    "df_com_bod.shape\n",
    "\n",
    "# Comments\n",
    "df_com = df_samp[df_samp['submission']==0]\n",
    "df_com = df_com[['sub', 'body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['self_post'] == 1].shape\n",
    "# There are only 286 self posts in the dataset of both subreddits, \n",
    "# too small to do much with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will print out both scores for the model\n",
    "# Also, this creates a dictionary of the model and adds it to a list\n",
    "# This is so I can store it and access it later\n",
    "def scoring(name, model, X_train, X_test, y_train, y_test):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print(f'{name} - Training: {train_score:.2%}')\n",
    "    print(f'{name} - Testing: {test_score:.2%}')\n",
    "    print('*'*15)\n",
    "    models.append({'model_name' : name,\n",
    "           'model' : model,\n",
    "           'training_score' : train_score,\n",
    "           'testing_score' : test_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test/split the same for all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I was running train, test, split with the same parameters\n",
    "# Build this since it is shorter \n",
    "def ttt(X, y):\n",
    "    return train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to iterate over\n",
    "pipe_params = {\n",
    "    'vect__max_features' : [2500, 5000, None],\n",
    "    'vect__ngram_range' : [(1,1), (1,2)],\n",
    "    'vect__max_df' : [.9, .95],\n",
    "    'vect__min_df' : [None, .05],\n",
    "    'vect__stop_words' : [None, 'english']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Regression code\n",
    "# Instantiates and fits the model returning the best performing one\n",
    "# This was just easier since I was running this with the same \n",
    "# parameters each time\n",
    "def nb_regging(X_train, y_train):\n",
    "    pipe_nb = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('nb', BernoulliNB())\n",
    "])\n",
    "    gs = GridSearchCV(pipe_nb,\n",
    "                 pipe_params,\n",
    "                 cv=5,\n",
    "                 n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Regression\n",
    "# This instantiates and fits the SVC\n",
    "# Added in a few additional parameters to check here\n",
    "# Using 2 degree polynomial is on the recomendation from Tim Book's lesson\n",
    "def svc_regging(X_train, y_train):\n",
    "    pipe_params_svc = pipe_params.copy()\n",
    "    pipe_params_svc['svc__degree'] = [2, 3]\n",
    "    pipe_params_svc['svc__kernel'] = ['poly', 'rbf']\n",
    "    pipe_svc = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "    gs = GridSearchCV(pipe_svc,\n",
    "                 pipe_params,\n",
    "                 cv=5,\n",
    "                 n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression/Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Fuction\n",
    "# Similar to the two above, just to keep it cleaner\n",
    "def log_regging(X_train, y_train):\n",
    "    pipe_log = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "    gs = GridSearchCV(pipe_log,\n",
    "                 pipe_params,\n",
    "                 cv=5,\n",
    "                     n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Title - LogisticReg - Training: 68.79%\n",
      "Submission Title - LogisticReg - Testing: 64.91%\n",
      "***************\n",
      "Submission Title - NB - Training: 68.79%\n",
      "Submission Title - NB - Testing: 64.91%\n",
      "***************\n",
      "Submission Title - SVC - Training: 75.15%\n",
      "Submission Title - SVC - Testing: 64.91%\n",
      "***************\n",
      "Submission Body and Comments - LogisticReg - Training: 60.70%\n",
      "Submission Body and Comments - LogisticReg - Testing: 60.00%\n",
      "***************\n",
      "Submission Body and Comments - NB - Training: 58.53%\n",
      "Submission Body and Comments - NB - Testing: 58.38%\n",
      "***************\n",
      "Submission Body and Comments - SVC - Training: 58.53%\n",
      "Submission Body and Comments - SVC - Testing: 58.38%\n",
      "***************\n",
      "Comments - LogisticReg - Training: 60.73%\n",
      "Comments - LogisticReg - Testing: 59.94%\n",
      "***************\n",
      "Comments - NB - Training: 58.82%\n",
      "Comments - NB - Testing: 58.50%\n",
      "***************\n",
      "Comments - SVC - Training: 58.82%\n",
      "Comments - SVC - Testing: 58.50%\n",
      "***************\n",
      "CPU times: user 1min 44s, sys: 12.1 s, total: 1min 56s\n",
      "Wall time: 13min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = []\n",
    "# Ran the same test, train, split on each dataset\n",
    "# Based on Submission Title\n",
    "# logistic regression\n",
    "X_train, X_test, y_train, y_test = ttt(df_titles['title'], df_titles['sub'])\n",
    "lr_mod = log_regging(X_train, y_train)\n",
    "scoring('Submission Title - LogisticReg', lr_mod, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "\n",
    "nb_mod = nb_regging(X_train, y_train)\n",
    "scoring('Submission Title - NB', nb_mod, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Support Vector Classification\n",
    "\n",
    "svc_mod = svc_regging(X_train, y_train)\n",
    "scoring('Submission Title - SVC', svc_mod, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Based on Submission Body(self-post) and Comments\n",
    "# Logistic Regression\n",
    "X_train, X_test, y_train, y_test = ttt(df_com_bod['body'], df_com_bod['sub'])\n",
    "lr_mod = log_regging(X_train, y_train)\n",
    "scoring('Submission Body and Comments - LogisticReg', lr_mod, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "\n",
    "nb_mod = nb_regging(X_train, y_train)\n",
    "scoring('Submission Body and Comments - NB', nb_mod, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Support Vector Classification\n",
    "\n",
    "svc_mod = svc_regging(X_train, y_train)\n",
    "scoring('Submission Body and Comments - SVC', nb_mod, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Based on Comments\n",
    "# Logistic Regression\n",
    "X_train, X_test, y_train, y_test = ttt(df_com['body'], df_com['sub'])\n",
    "lr_mod = log_regging(X_train, y_train)\n",
    "scoring('Comments - LogisticReg', lr_mod, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "\n",
    "nb_mod = nb_regging(X_train, y_train)\n",
    "scoring('Comments - NB', nb_mod, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Support Vector Classification\n",
    "\n",
    "svc_mod = svc_regging(X_train, y_train)\n",
    "scoring('Comments - SVC', nb_mod, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission Title - LogisticReg - Training: 0.6878808395396073\n",
    "Submission Title - LogisticReg - Testing: 0.6490872210953347\n",
    "***************\n",
    "Submission Title - NB - Training: 0.6878808395396073\n",
    "Submission Title - NB - Testing: 0.6490872210953347\n",
    "***************\n",
    "Submission Title - SVC - Training: 0.7515233581584293\n",
    "Submission Title - SVC - Testing: 0.6490872210953347\n",
    "***************\n",
    "Submission Body and comments - LogisticReg - Training: 0.6221395954801093\n",
    "Submission Body and comments - LogisticReg - Testing: 0.6205155161127002\n",
    "***************\n",
    "Submission Body and comments - NB - Training: 0.6221395954801093\n",
    "Submission Body and comments - NB - Testing: 0.6205155161127002\n",
    "***************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.9, max_features=2500,\n",
       "                                 min_df=0.05, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[2]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.9, max_features=2500,\n",
       "                                 min_df=0.05, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[3]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.9, max_features=2500,\n",
       "                                 min_df=0.05, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[6]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
